{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)\n",
    "\n",
    "Se ve que hay 1462 datos y se tiene información como la humedad, velocidad del viento, presión media, dia de la semana, año, mes y la estación.\n",
    "\n",
    "No es correcto predecir la temperatura solo con el dia anterior, porque no hay correlación directa entre los comportamientos. Una dia puede que este soleado y la temperatura sea mayor y puede que el día siguiente este nublado y la temperatura baje drásticamente.\n",
    "\n",
    "## b)\n",
    "La ventanja de utilizar árboles de desición es no tener que escalar los datos. Sin embargo, puede ser útil para la visualización de estos. No es necesario escalarlos dado que escalarlos solo los mueve en el espacio, entonces si bien el criterio para separarlos en dos grupos cambia númericamente, el resultado es el mismo.\n",
    "\n",
    "## c)\n",
    "\n",
    "Se ve una notoria diferencia en los resultados, en donde el regularizado tiene un rendimiento mucho mejor. Además el modelo regularizado visualmente es mucho más suave en comparación con el no regularizado.\n",
    "\n",
    "## d)\n",
    "\n",
    "El uso de ensamblados deberia mejorar el rendimiento de ambos.No se vizualiza overfitting, porque al aumentar el número de estimadores el RMSE del set set validación se mantiene constante.\n",
    "\n",
    "## e)\n",
    " En caso del no regularizado se ve overfitting. Por otro lado el regularizado al igual que en caso anterior no se ve overfitting por los mismos motivos. Sk-learn utiliza pesar ejemplos. Dado que es difícil crear la noción de que sean modelos independientes, ambas parecen opciones sensatas. Por un lado, re muestreo genera una noción más marcada de \"independecia\" entre los modelos, pero no ocupa todo los datos para cada modelo. Por otro lado, el pesar ejemplos sí ocupa todos los datos, pero pierde un poco la noción de \"independencia\" entre los modelos.\n",
    " \n",
    "## f)\n",
    "No se visualiza overfitting. Se ve que los resultados no varian substancialmente que con la otra técnica.\n",
    "\n",
    "## g)\n",
    "Se ve que ambos valores son muy similares y por lo tanto se puede utilizar como alternativa de la métrica de generalización.\n",
    "\n",
    "## h)\n",
    "\n",
    "En este caso se decidio utilizar la mediana de las predicciones. \n",
    "\n",
    "## i)\n",
    "\n",
    "Se ve que las prediciones del modelo caen dentro del intervalo de confianza, por lo que se reafirma la validez del modelo.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
